---
title: "Homework8"
format: html
editor: visual
---

# Reading Data

```{r}
#| output: false

library(readr)
library(tidyverse)
library(lubridate)
library(corrr)
library(tidymodels)

df <- readr::read_csv("SeoulBikeData.csv", locale=locale(encoding="latin1"))
head(df)
```

# EDA

First, let's rename the columns to make them easier to work with:
```{r}
colnames(df) <- gsub(" ", "_", colnames(df))

df <- df |>
  rename("Temperature_C"="Temperature(°C)") |>
  rename("Humidity_Percent"="Humidity(%)") |>
  rename("Wind_speed_m_per_s"="Wind_speed_(m/s)") |>
  rename("Visibility_10m"="Visibility_(10m)") |>
  rename("Dew_point_temperature_C"="Dew_point_temperature(°C)") |>
  rename("Solar_Radiation_MJ_per_sq_m"="Solar_Radiation_(MJ/m2)") |>
  rename("Rainfall_mm"="Rainfall(mm)") |>
  rename("Snowfall_cm"="Snowfall_(cm)")

head(df)
```

Let's do some checking to validate the dataset before we build a model with it:

```{r}
# check for missing values
sum_na <- function(column){
 sum(is.na(column))
}

na_counts <- df |>
 summarize(across(everything(), sum_na))

na_counts
```

There are no NA values in our data. What are the values seen?

```{r}
cat_vars <- c("Date", "Seasons", "Holiday", "Functioning_Day")

for (var in cat_vars){
  print(head(unique(df[var])))
}

table(df$Seasons)
table(df$Holiday)
table(df$Functioning_Day)
```

Convert the Date column to actual date type and other categorical variables into factors:

```{r}
df <- df |>
  mutate(Date = parse_date_time(Date, "dmy")) |>
  mutate(Seasons = as.factor(Seasons)) |>
  mutate(Holiday = as.factor(Holiday))|>
  mutate(Functioning_Day = as.factor(Functioning_Day))

df
```

Calculate summaries to check in with numeric variables:

```{r}
# function for finding measures of center and spread
find_center_and_spread <- function(df) {
  return(df|>
    summarize(across(where(is.numeric), 
               list("mean" = mean, "median" = median, "sd"=sd, "IQR"=IQR), 
               .names = "{.fn}_{.col}")))
}

# find centers and spread for all numeric vars
find_center_and_spread(df)
```

Now that we have cleaned up our column names and datatypes, as well as validated the values in the dataset and confirmed there are no missing values, let's look more into the relationships between our target variable (Rented_Bike_Count) and other variables.

```{r}
# summarize across categorical variables
# function for finding measures of center and spread
find_center_and_spread_grouped <- function(df, group) {
  return(df|>
    group_by({{group}}) |>
    summarize(across(where(is.numeric), 
               list("mean" = mean, "median" = median, "sd"=sd, "IQR"=IQR), 
               .names = "{.fn}_{.col}")))
}

# find centers and spread for all numeric vars, grouped by cat vars
find_center_and_spread_grouped(df, Seasons)
find_center_and_spread_grouped(df, Holiday)
find_center_and_spread_grouped(df, Functioning_Day)
```

Notes: 

- All Rented_Bike_Count values are 0 for Functioning_Day=No. Since the effects of other variables cannot influence the rentals on these days, we can filter them out to get a better picture of how the other variables influence the target.
- Rented_Bike_Count is lower for holidays.
- Rented_Bike_Count is highest in summer, followed by autumn, spring, and winter.

Subset the data to filter out Functioning_Day=No:

```{r}
df_filtered <- df |>
  filter(Functioning_Day=='Yes')

df
df_filtered
```

Combine the rows into 1 row for each day:

```{r}
day_df <- df_filtered |>
  group_by(Date, Seasons, Holiday) |>
  summarise(across(c(Rented_Bike_Count, Rainfall_mm, Snowfall_cm), sum), 
            across(c(Temperature_C, Humidity_Percent, Wind_speed_m_per_s, Visibility_10m, Dew_point_temperature_C, Solar_Radiation_MJ_per_sq_m), 
                   mean),
            .groups='drop')

head(day_df)
```

Now that the data has been combined for each day, we'll take another look at our summary statistics for categorical and numerical variables:

```{r}
# categorical vars:
table(day_df$Seasons)
table(day_df$Holiday)

# numerical vars:
find_center_and_spread(day_df)

find_center_and_spread_grouped(day_df, Seasons)
find_center_and_spread_grouped(day_df, Holiday)
```

Exploring relationships: plots and correlation values

```{r}
# categorical vars
ggplot(day_df, aes(x = Rented_Bike_Count)) + geom_density(alpha = 0.5, aes(fill = Seasons)) + ggtitle("Rented Bike Count By Season")
ggplot(day_df, aes(x = Rented_Bike_Count)) + geom_density(alpha = 0.5, aes(fill = Holiday)) + ggtitle("Rented Bike Count By Holiday")
```

```{r}
# numerical vars
ggplot(day_df, aes(x = Seasons, y = Rented_Bike_Count, color = Seasons)) + geom_point(position = "jitter") + ggtitle("Rented Bike Count by Season")
ggplot(day_df, aes(x = Rainfall_mm, y = Rented_Bike_Count)) + geom_point(position = "jitter") + ggtitle("Rented Bike Count vs. Rainfall")
ggplot(day_df, aes(x = Humidity_Percent, y = Rented_Bike_Count)) + geom_point(position = "jitter") + ggtitle("Rented Bike Count vs. Humidity")
ggplot(day_df, aes(x = Wind_speed_m_per_s, y = Rented_Bike_Count)) + geom_point(position = "jitter") + ggtitle("Rented Bike Count vs. Wind Speed")

# correlation
day_df |>
  select(where(is.numeric)) |>
  correlate()
```

Notes:

- The correlation with Rented Bike Count is strongest for Temperature, Dew Point Temperature, and Solar Radiation.

# Split the Data

We'll split our data into training and test sets, stratified by the variable Seasons, and then create our 10 folds for 10-fold cross validation.

```{r}
day_split <- initial_split(day_df, prop=0.75, strata=Seasons)
day_train <- training(day_split)
day_test <- testing(day_split)

day_10_fold <- vfold_cv(day_train, 10)
```

# Fitting MLR Models

Creating 3 recipes:

```{r}
# recipe #1
recipe_1 <- recipe(Rented_Bike_Count ~ ., data=day_train) |>
  step_date(Date) |>
  step_mutate(day_type=factor(if_else(Date_dow %in% c('Sat', 'Sun'), 'weekday', 'weekend'))) |>
  step_rm(Date, Date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(Seasons, Holiday, day_type)
```

```{r}
# recipe #2
recipe_2 <- recipe(Rented_Bike_Count ~ ., data=day_train) |>
  step_date(Date) |>
  step_mutate(day_type=factor(if_else(Date_dow %in% c('Sat', 'Sun'), 'weekday', 'weekend'))) |>
  step_rm(Date, Date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(Seasons, Holiday, day_type) |>
  step_interact(terms = ~starts_with("Seasons")*starts_with("Holiday")) |>
  step_interact(terms = ~starts_with("Seasons")*Temperature_C) |>
  step_interact(terms = ~Temperature_C*Rainfall_mm)
```

```{r}
# recipe #3
recipe_3 <- recipe(Rented_Bike_Count ~ ., data=day_train) |>
  step_date(Date) |>
  step_mutate(day_type=factor(if_else(Date_dow %in% c('Sat', 'Sun'), 'weekday', 'weekend'))) |>
  step_rm(Date, Date_dow) |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_dummy(Seasons, Holiday, day_type) |>
  step_interact(terms = ~starts_with("Seasons")*starts_with("Holiday")) |>
  step_interact(terms = ~starts_with("Seasons")*Temperature_C) |>
  step_interact(terms = ~Temperature_C*Rainfall_mm) |>
  step_poly(Rainfall_mm, Snowfall_cm, Temperature_C, Humidity_Percent, Wind_speed_m_per_s, Visibility_10m, Dew_point_temperature_C, Solar_Radiation_MJ_per_sq_m)
```

Set up a linear model:

```{r}
day_mod <- linear_reg() |>
  set_engine("lm")
```

Train with 10-fold CV with each recipe and look at the metrics for all:

```{r}
day_CV_fits_1 <- workflow() |>
  add_recipe(recipe_1) |>
  add_model(day_mod) |>
  fit_resamples(day_10_fold)

day_CV_fits_2 <- workflow() |>
  add_recipe(recipe_2) |>
  add_model(day_mod) |>
  fit_resamples(day_10_fold)

day_CV_fits_3 <- workflow() |>
  add_recipe(recipe_3) |>
  add_model(day_mod) |>
  fit_resamples(day_10_fold)

rbind(day_CV_fits_1 |> collect_metrics(),
 day_CV_fits_2 |> collect_metrics(),
 day_CV_fits_3 |> collect_metrics())
```

Best model: recipe #1!

Now let's train using recipe 1 with the entire training dataset:

```{r}
day_wfl <- workflow() |>
  add_recipe(recipe_1) |>
  add_model(day_mod)

fit <- day_wfl |>
  last_fit(day_split)

# test set metrics
fit |>
  collect_metrics()
```

Finally, let's train on the entire dataset:

```{r}
# fit on all data
full_fit <-day_wfl |>
  fit(day_df)

full_fit |>
  extract_fit_parsnip() |>
  tidy()
```
